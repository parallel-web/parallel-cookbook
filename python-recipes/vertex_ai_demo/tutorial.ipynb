{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertex AI + Parallel Web Search Grounding Tutorial\n",
    "\n",
    "This notebook teaches you how to ground Gemini responses with real-time web data using Parallel's web search API.\n",
    "\n",
    "**What you'll learn:**\n",
    "1. How the Parallel grounding integration works\n",
    "2. How to make grounded API calls to Vertex AI\n",
    "3. How to parse sources and citations from responses\n",
    "4. How to compare grounded vs. ungrounded responses\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. A Google Cloud project with Vertex AI API enabled\n",
    "2. A Parallel API key from https://parallel.ai/products/search\n",
    "3. Google Cloud authentication configured (`gcloud auth application-default login`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "First, let's configure our credentials and imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "import requests\n",
    "\n",
    "# Load from .env file if available\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration - set these or use environment variables\n",
    "PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
    "PARALLEL_API_KEY = os.environ.get(\"PARALLEL_API_KEY\")\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "# Validate setup\n",
    "assert PROJECT_ID, \"Set GOOGLE_CLOUD_PROJECT environment variable\"\n",
    "assert PARALLEL_API_KEY, \"Set PARALLEL_API_KEY environment variable\"\n",
    "print(f\"Project: {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Understanding the Grounding Config\n",
    "\n",
    "To enable Parallel web search grounding, we add a `tools` parameter to our API request. Here's the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_grounding_config(api_key: str, max_results: int = 10) -> dict:\n",
    "    \"\"\"\n",
    "    Build the grounding configuration for Parallel web search.\n",
    "    \n",
    "    This config tells Vertex AI to use Parallel's web search API\n",
    "    to ground the model's responses with real-time web data.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"parallelAiSearch\": {\n",
    "            \"api_key\": api_key,\n",
    "            # Optional: customize search behavior\n",
    "            # \"customConfigs\": {\n",
    "            #     \"max_results\": 5,\n",
    "            #     \"source_policy\": {\n",
    "            #         \"include_domains\": [\"reuters.com\", \"bbc.com\"],\n",
    "            #         \"exclude_domains\": [\"twitter.com\"]\n",
    "            #     }\n",
    "            # }\n",
    "        }\n",
    "    }\n",
    "\n",
    "grounding_config = build_grounding_config(PARALLEL_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Making a Grounded API Call\n",
    "\n",
    "Now let's build a function to call the Vertex AI API with grounding enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_access_token():\n",
    "    \"\"\"Get a Google Cloud access token for API authentication.\"\"\"\n",
    "    credentials, _ = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    credentials.refresh(auth_req)\n",
    "    return credentials.token\n",
    "\n",
    "\n",
    "def generate_with_grounding(prompt: str, model_id: str = \"gemini-2.5-flash\") -> dict:\n",
    "    \"\"\"\n",
    "    Call Vertex AI Gemini with Parallel web search grounding.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The question to ask\n",
    "        model_id: Which Gemini model to use\n",
    "        \n",
    "    Returns:\n",
    "        The raw API response as a dictionary\n",
    "    \"\"\"\n",
    "    # Build the API endpoint URL\n",
    "    url = f\"https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/{model_id}:generateContent\"\n",
    "    \n",
    "    # Build the request body\n",
    "    request_body = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [{\"text\": prompt}]\n",
    "            }\n",
    "        ],\n",
    "        # This is the key part - adding the grounding tool\n",
    "        \"tools\": [build_grounding_config(PARALLEL_API_KEY)],\n",
    "        \"generationConfig\": {\n",
    "            \"temperature\": 0.2\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Make the API call\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {get_access_token()}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        json=request_body,\n",
    "        timeout=120,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def generate_without_grounding(prompt: str, model_id: str = \"gemini-2.5-flash\") -> dict:\n",
    "    \"\"\"\n",
    "    Call Vertex AI Gemini WITHOUT grounding (for comparison).\n",
    "    \"\"\"\n",
    "    url = f\"https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/{model_id}:generateContent\"\n",
    "    \n",
    "    request_body = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [{\"text\": prompt}]\n",
    "            }\n",
    "        ],\n",
    "        # No \"tools\" parameter = no grounding\n",
    "        \"generationConfig\": {\n",
    "            \"temperature\": 0.2\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        url,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {get_access_token()}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        json=request_body,\n",
    "        timeout=120,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Make Your First Grounded Request\n",
    "\n",
    "Let's ask a question that requires recent information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question about recent events\n",
    "question = \"Who won the most recent Super Bowl?\"\n",
    "raw_response = generate_with_grounding(question)\n",
    "\n",
    "# Let's look at the raw response structure\n",
    "print(\"Response keys:\", raw_response.keys())\n",
    "print(\"\\nCandidate keys:\", raw_response[\"candidates\"][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Parsing the Response\n",
    "\n",
    "The API response has a specific structure. Let's write a function to extract the useful parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_grounded_response(response: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Parse a grounded API response into a clean format.\n",
    "    \n",
    "    Response structure:\n",
    "    {\n",
    "        \"candidates\": [{\n",
    "            \"content\": {\n",
    "                \"parts\": [{\"text\": \"The answer...\"}]\n",
    "            },\n",
    "            \"groundingMetadata\": {\n",
    "                \"webSearchQueries\": [\"query1\", \"query2\"],\n",
    "                \"groundingChunks\": [\n",
    "                    {\"web\": {\"uri\": \"https://...\", \"title\": \"Page Title\"}}\n",
    "                ],\n",
    "                \"groundingSupports\": [...]\n",
    "            }\n",
    "        }]\n",
    "    }\n",
    "    \"\"\"\n",
    "    candidate = response.get(\"candidates\", [{}])[0]\n",
    "    \n",
    "    # Extract the generated text\n",
    "    content = candidate.get(\"content\", {})\n",
    "    parts = content.get(\"parts\", [])\n",
    "    text = parts[0].get(\"text\", \"\") if parts else \"\"\n",
    "    \n",
    "    # Extract grounding metadata\n",
    "    grounding = candidate.get(\"groundingMetadata\", {})\n",
    "    \n",
    "    # Extract search queries the model executed\n",
    "    queries = grounding.get(\"webSearchQueries\", [])\n",
    "    \n",
    "    # Extract sources (URLs and titles)\n",
    "    sources = []\n",
    "    for chunk in grounding.get(\"groundingChunks\", []):\n",
    "        web_info = chunk.get(\"web\", {})\n",
    "        if web_info:\n",
    "            sources.append({\n",
    "                \"uri\": web_info.get(\"uri\", \"\"),\n",
    "                \"title\": web_info.get(\"title\", \"Untitled\")\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"sources\": sources,\n",
    "        \"queries\": queries\n",
    "    }\n",
    "\n",
    "\n",
    "# Parse our response\n",
    "result = parse_grounded_response(raw_response)\n",
    "\n",
    "# Display nicely\n",
    "sources_md = \"\\n\".join([f\"- [{s['title']}]({s['uri']})\" for s in result[\"sources\"][:5]])\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### Answer\n",
    "\n",
    "{result[\"text\"]}\n",
    "\n",
    "---\n",
    "\n",
    "**Sources ({len(result['sources'])}):**\n",
    "\n",
    "{sources_md}\n",
    "\n",
    "**Search queries:** {result['queries']}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Compare Grounded vs. Ungrounded\n",
    "\n",
    "Let's see the difference grounding makes for time-sensitive questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_responses(question: str):\n",
    "    \"\"\"Compare grounded vs ungrounded responses side by side.\"\"\"\n",
    "    \n",
    "    # Get both responses\n",
    "    grounded_raw = generate_with_grounding(question)\n",
    "    ungrounded_raw = generate_without_grounding(question)\n",
    "    \n",
    "    # Parse them\n",
    "    grounded = parse_grounded_response(grounded_raw)\n",
    "    ungrounded_text = ungrounded_raw[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "    \n",
    "    sources_md = \"\\n\".join([f\"- [{s['title']}]({s['uri']})\" for s in grounded[\"sources\"][:3]])\n",
    "    \n",
    "    display(Markdown(f\"\"\"\n",
    "## Question: {question}\n",
    "\n",
    "---\n",
    "\n",
    "### Without Grounding (training data only)\n",
    "\n",
    "{ungrounded_text}\n",
    "\n",
    "---\n",
    "\n",
    "### With Parallel Grounding (real-time web)\n",
    "\n",
    "{grounded[\"text\"]}\n",
    "\n",
    "**Sources:**\n",
    "\n",
    "{sources_md}\n",
    "\"\"\"))\n",
    "\n",
    "# Try it!\n",
    "compare_responses(\"What was the final score of the most recent Los Angeles Lakers game?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another question\n",
    "compare_responses(\"What were the results of the most recent NBA Finals?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Custom Grounding Configuration\n",
    "\n",
    "You can customize the grounding behavior - for example, restricting to specific domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_custom_grounding(\n",
    "    prompt: str,\n",
    "    include_domains: list = None,\n",
    "    exclude_domains: list = None,\n",
    "    max_results: int = 10,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Call Vertex AI with customized grounding configuration.\n",
    "    \"\"\"\n",
    "    url = f\"https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/gemini-2.5-flash:generateContent\"\n",
    "    \n",
    "    # Build custom grounding config\n",
    "    grounding_config = {\n",
    "        \"parallelAiSearch\": {\n",
    "            \"api_key\": PARALLEL_API_KEY,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add custom configurations if specified\n",
    "    custom_configs = {}\n",
    "    if max_results != 10:\n",
    "        custom_configs[\"max_results\"] = max_results\n",
    "    \n",
    "    source_policy = {}\n",
    "    if include_domains:\n",
    "        source_policy[\"include_domains\"] = include_domains\n",
    "    if exclude_domains:\n",
    "        source_policy[\"exclude_domains\"] = exclude_domains\n",
    "    if source_policy:\n",
    "        custom_configs[\"source_policy\"] = source_policy\n",
    "        \n",
    "    if custom_configs:\n",
    "        grounding_config[\"parallelAiSearch\"][\"customConfigs\"] = custom_configs\n",
    "    \n",
    "    request_body = {\n",
    "        \"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": prompt}]}],\n",
    "        \"tools\": [grounding_config],\n",
    "        \"generationConfig\": {\"temperature\": 0.2}\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        url,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {get_access_token()}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        json=request_body,\n",
    "        timeout=120,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "# Example: Only use trusted news sources\n",
    "response = generate_with_custom_grounding(\n",
    "    prompt=\"What is the latest AI news?\",\n",
    "    include_domains=[\"theverge.com\", \"techcrunch.com\", \"wired.com\", \"reuters.com\"],\n",
    "    max_results=5\n",
    ")\n",
    "\n",
    "result = parse_grounded_response(response)\n",
    "sources_md = \"\\n\".join([f\"- {s['uri']}\" for s in result[\"sources\"]])\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### News from trusted sources only\n",
    "\n",
    "{result[\"text\"]}\n",
    "\n",
    "**Sources used:**\n",
    "\n",
    "{sources_md}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Try Your Own Questions!\n",
    "\n",
    "Experiment with different questions to see how grounding helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own question!\n",
    "your_question = \"What were the key announcements at the latest Google I/O?\"\n",
    "\n",
    "response = generate_with_grounding(your_question)\n",
    "result = parse_grounded_response(response)\n",
    "\n",
    "sources_md = \"\\n\".join([f\"- [{s['title']}]({s['uri']})\" for s in result[\"sources\"][:5]])\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### Q: {your_question}\n",
    "\n",
    "{result[\"text\"]}\n",
    "\n",
    "---\n",
    "\n",
    "**Sources:**\n",
    "\n",
    "{sources_md}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned:\n",
    "\n",
    "1. **Grounding config** - Add `tools: [{\"parallelAiSearch\": {\"api_key\": \"...\"}}]` to your request\n",
    "2. **Making calls** - Use the standard Vertex AI REST API with the grounding tool\n",
    "3. **Parsing responses** - Extract text from `candidates[0].content.parts[0].text` and sources from `groundingMetadata.groundingChunks`\n",
    "4. **Customization** - Use `customConfigs` to filter domains and limit results\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Check out `quickstart.py` for a minimal example using the helper library\n",
    "- See `demo.py` for a command-line demo\n",
    "- Read the [Vertex AI documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-parallel) for more options"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
